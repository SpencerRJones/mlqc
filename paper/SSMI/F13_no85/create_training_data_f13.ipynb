{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d857a29-9e0a-4c81-93a9-08dc5abd72cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Creates training data for F13 channel predictor\n",
    "'''\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from util_funcs.L1C import scantime2datetime\n",
    "from util_funcs import data2xarray, array_funcs\n",
    "import geography\n",
    "\n",
    "satellite = 'F13'\n",
    "sensor = 'SSMI'\n",
    "\n",
    "datapath = f'/edata1/archive/GPM/1C_{satellite}_V7/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671040bc-2bfa-413c-ab81-01c896fb37af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Files:  36%|████████▋               | 72/200 [08:50<11:15,  5.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all were bad.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Files:  54%|████████████▎          | 107/200 [13:11<11:01,  7.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all were bad.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Files:  94%|█████████████████████▌ | 188/200 [24:29<01:31,  7.59s/it]"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Satellite: F13\n",
    "\n",
    "Get data and quality check for training.\n",
    "\n",
    "nscans: generally around 1600 & 3200\n",
    "npixs: 64 & 128\n",
    "\n",
    "Tb array will be set up as follows:\n",
    "    Tbs =  [m x n], where m is the number of samples and n is the\n",
    "           number of channels (features)\n",
    "    1-2:   19.35 V and H\n",
    "    3:     22.235 V\n",
    "    4-5:   37.0 V and H\n",
    "    6-9:   85.5 V and H #Double-sampled 85\n",
    "\n",
    "Change cell to code to start from scratch.\n",
    "'''\n",
    "\n",
    "#Set up a random seed for reproducibility\n",
    "np.random.seed(12)\n",
    "\n",
    "\n",
    "\n",
    "#Get a random list of files\n",
    "file_list = glob.glob(f'{datapath}*/*/1C.{satellite}.SSMI.*.HDF5'); file_list.sort()\n",
    "#Everything looks good before about 2008:\n",
    "good_files = [ifile for ifile in file_list if int(ifile.split('/')[5]) < 801 \n",
    "              and int(ifile.split('/')[5]) != 406 \n",
    "              and int(ifile.split('/')[5]) != 203]\n",
    "\n",
    "flist = np.random.choice(good_files, size=200)\n",
    "\n",
    "tb_dim = 9\n",
    "qual_dim = 2\n",
    "\n",
    "#Loop through files and get good quality data.\n",
    "for i, ifile in enumerate(tqdm(flist, desc=\"Processing Files\")):\n",
    "\n",
    "    #print(f'{i+1} of {len(flist)}, {ifile}')\n",
    "\n",
    "    with xr.open_dataset(ifile, group='S1', decode_timedelta=False) as f:\n",
    "        lat = f.Latitude.values\n",
    "        lon = f.Longitude.values\n",
    "\n",
    "    nscans, npixs = lat.shape\n",
    "    Tbs = np.zeros([nscans,npixs,tb_dim], dtype=np.float32)\n",
    "    qual = np.zeros([nscans,npixs,qual_dim], dtype=np.int32)\n",
    "\n",
    "    with xr.open_dataset(ifile, group='S1', decode_timedelta=False) as f:\n",
    "        qual[:,:,0] = f.Quality.values\n",
    "        Tbs[:,:,0:2] = f.Tc[:,:,0:2].values #19V and H\n",
    "        Tbs[:,:,2]   = f.Tc[:,:,2].values #22V\n",
    "        Tbs[:,:,3:5] = f.Tc[:,:,3:5].values #37V and H\n",
    "\n",
    "    with xr.open_dataset(ifile, group='S2', decode_timedelta=False) as f:\n",
    "        #Even-numbered scans line up with S1 Scans (0,2,4,...)\n",
    "        qual[:,:,1] = f.Quality.values[::2,::2]\n",
    "        Tbs[:,:,5] = f.Tc.values[::2,::2,0] #85V, even scans, even pixs\n",
    "        Tbs[:,:,6] = f.Tc.values[::2,::2,1] #85H, even scans, even pixs\n",
    "        Tbs[:,:,7] = f.Tc.values[::2,1::2,0] #85V, even scans, odd pixs\n",
    "        Tbs[:,:,8] = f.Tc.values[::2,1::2,1] #85H, even scans, odd pixs\n",
    "\n",
    "    with xr.open_dataset(ifile, group='S1/ScanTime', decode_timedelta=False) as f:\n",
    "        scantime = (f.Year.values, f.Month.values, f.DayOfMonth.values, f.Hour.values, f.Minute.values, f.Second.values)\n",
    "\n",
    "    #Change scan time format from L1C to datetime format for easier use\n",
    "    scantime = scantime2datetime(scantime)\n",
    "\n",
    "    #Get only good quality data and reshape:\n",
    "    goodqual = np.all(qual == 0, axis=2)\n",
    "    all_bad = np.all(goodqual == False)\n",
    "    if all_bad:\n",
    "        print('all were bad.')\n",
    "        continue\n",
    "    lat = lat[goodqual]\n",
    "    lon = lon[goodqual]\n",
    "    scantime = scantime[np.where(goodqual)[0]]\n",
    "    Tbs = Tbs[goodqual]\n",
    "\n",
    "    #Check for NaNs (shouldn't be any if all good, but I've seen some)\n",
    "    nonans = array_funcs.find_nan_rows(Tbs, return_good=True)\n",
    "    Tbs = Tbs[nonans]\n",
    "    lat = lat[nonans]\n",
    "    lon = lon[nonans]\n",
    "    scantime = scantime[nonans]\n",
    "    \n",
    "\n",
    "    #Attach GPROF surface map data to each pixel\n",
    "    sfctype = geography.attach_gpm_sfctype(lat, lon, scantime, sensor=sensor)\n",
    "\n",
    "    npixs = lat.size\n",
    "\n",
    "    #Output as NetCDF\n",
    "    dset = data2xarray(data_vars = [lat, lon, scantime, sfctype, Tbs],\n",
    "                       var_names = ['latitude', 'longitude', 'scantime', 'sfctype', 'Tbs'],\n",
    "                       dims = [npixs, tb_dim],\n",
    "                       dim_names = ['pixels', 'channels'])\n",
    "\n",
    "\n",
    "    if i == 0:\n",
    "        training_dataset = dset\n",
    "    else:\n",
    "        training_dataset = xr.concat((training_dataset, dset), dim='pixels')\n",
    "\n",
    "training_dataset.to_netcdf(f'training_data/{satellite}_training_data.nc', engine='netcdf4')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
