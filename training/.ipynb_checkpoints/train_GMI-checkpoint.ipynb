{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cf78017-58d1-4da3-8f0c-a04cdc61871c",
   "metadata": {},
   "source": [
    "# Channel Prediction Model for Quality Control\n",
    "\n",
    "This notebook contains the code and outlines the development of the\n",
    "GMI Channel Prediction Neural Network for QC purposes of GMI L1C\n",
    "data. The simple Feed-Forward Neural Networks (FFNNs) are trained on\n",
    "good quality brightness temperature observation vectors and are\n",
    "trained to predict one channel from all the others as predictors.\n",
    "\n",
    "The end product is a tree of FFNNs, discretized by surface (ocean or \n",
    "land), and by channel, since these are fully distinct problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3ba314-201a-4c7d-8180-ad6c83f31509",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import glob\n",
    "import torch\n",
    "from torch import nn\n",
    "import paths\n",
    "from src.utils import data2xarray, array_funcs, extract_channel\n",
    "from src import surface, sensor_info, training_funcs\n",
    "from src.classes.dataset_class import dataset\n",
    "from src.classes.model_class import channel_predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda70559-4a08-44c3-8868-81b1813d9191",
   "metadata": {},
   "outputs": [],
   "source": [
    "#General parameters\n",
    "satellite = sensor_info.satellite\n",
    "sensor = sensor_info.sensor\n",
    "\n",
    "nchans = sensor_info.nchannels\n",
    "batch_size = 1000\n",
    "input_size = nchans - 1\n",
    "hidden_size = 256\n",
    "output_size = 1\n",
    "\n",
    "#Number of cpus to use for parallelization\n",
    "ncpus = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec719b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "GMI CHANNEL PREDICTION MODEL:\n",
    "    1: Ocean\n",
    "\n",
    "'''\n",
    "\n",
    "sfc = [1]\n",
    "\n",
    "with xr.open_dataset(f'{paths.training_datapath}/{sensor_info.satellite}_training_data.nc') as f:\n",
    "    \n",
    "    sfctype = f.sfctype.values\n",
    "\n",
    "    correct_sfc = np.isin(sfctype, sfc)\n",
    "    sfcindcs = np.where(correct_sfc)[0]\n",
    "\n",
    "    Tbs = f.Tbs.values[sfcindcs]\n",
    "\n",
    "if Tbs.shape[0] > 5.0e+06:\n",
    "    Tbs = Tbs[:5_000_000,:]\n",
    "\n",
    "print(Tbs.shape)\n",
    "\n",
    "#---Split data into train/test/val:\n",
    "train_indcs, test_indcs, val_indcs = training_funcs.split_data_indcs(Tbs)\n",
    "\n",
    "Tbs_train = Tbs[train_indcs]\n",
    "Tbs_test  = Tbs[test_indcs]\n",
    "Tbs_val   = Tbs[val_indcs]\n",
    "\n",
    "#---Shuffle before converting to tensors:\n",
    "np.random.seed(40)\n",
    "Tbs_train = training_funcs.shuffle_data(Tbs_train, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5b5d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Predict channels: Train all models\n",
    "'''\n",
    "\n",
    "torch.set_num_threads(ncpus)\n",
    "\n",
    "for ichan, channel in enumerate(sensor_info.channel_descriptions):\n",
    "\n",
    "    print(channel)\n",
    "\n",
    "    x_train = Tbs_train\n",
    "    y_train = extract_channel(Tbs_train, channel)\n",
    "\n",
    "    #---Extract channel, x = predictors, y = channel to predict\n",
    "    x_train, y_train = extract_channel(Tbs_train, channel)\n",
    "    x_test,  y_test  = extract_channel(Tbs_test, channel)\n",
    "    x_val,   y_val   = extract_channel(Tbs_val, channel)\n",
    "    \n",
    "    x_train, y_train = torch.tensor(x_train), torch.tensor(y_train)\n",
    "    x_test,  y_test  = torch.tensor(x_test), torch.tensor(y_test)\n",
    "    x_val,   y_val   = torch.tensor(x_val), torch.tensor(y_val)\n",
    "\n",
    "\n",
    "    #---Set up dataloaders:\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=dataset(x_train,y_train), \n",
    "                                               batch_size=batch_size, \n",
    "                                               shuffle=True, drop_last=True)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=dataset(x_test,y_test), \n",
    "                                               batch_size=None, \n",
    "                                               shuffle=False, drop_last=False)\n",
    "    val_loader = torch.utils.data.DataLoader(dataset=dataset(x_val,y_val), \n",
    "                                               batch_size=None, \n",
    "                                               shuffle=False, drop_last=False)\n",
    "\n",
    "    #---Create model:\n",
    "    model = channel_predictor(input_size, hidden_size, output_size)\n",
    "\n",
    "    #---Train_model:\n",
    "    nbatches = len(train_loader)\n",
    "    nepochs_stage1 = 5\n",
    "    nepochs_stage2 = 10\n",
    "    nepochs_stage3 = 20\n",
    "\n",
    "    loss_stage1, valloss_stage1 = training_funcs.train_model(model, \n",
    "                                              nepochs=nepochs_stage1, \n",
    "                                              dataloader=train_loader, \n",
    "                                              learning_rate=0.001, \n",
    "                                              quiet=False, \n",
    "                                              stage=1, \n",
    "                                              validation_dataloader=val_loader)\n",
    "    \n",
    "    loss_stage2, valloss_stage2 = training_funcs.train_model(model, \n",
    "                                              nepochs=nepochs_stage2, \n",
    "                                              dataloader=train_loader, \n",
    "                                              learning_rate=0.001, \n",
    "                                              quiet=False, \n",
    "                                              stage=2, \n",
    "                                              validation_dataloader=val_loader)\n",
    "\n",
    "    loss_stage3, valloss_stage3 = training_funcs.train_model(model, \n",
    "                                              nepochs=nepochs_stage3, \n",
    "                                              dataloader=train_loader, \n",
    "                                              learning_rate=0.001, \n",
    "                                              quiet=False, \n",
    "                                              stage=3, \n",
    "                                              validation_dataloader=val_loader)\n",
    "\n",
    "    torch.save(model.state_dict(), \n",
    "               f'{model_path}/{sensor}/{sensor}_{satellite}_channel_predictor_{channel}_ocean.pt')\n",
    "\n",
    "    loss_data = data2xarray(data_vars = (loss_stage1, loss_stage2, loss_stage3, \n",
    "                                     valloss_stage1, valloss_stage2, valloss_stage3),\n",
    "                        var_names = ('LossStage1','LossStage2','LossStage3',\n",
    "                                     'ValidationLossStage1', 'ValidationLossStage2', 'ValidationLossStage3'),\n",
    "                        dims = (nbatches,nepochs_stage1,nepochs_stage2, nepochs_stage3),\n",
    "                        dim_names = ('training_batches', 'epochs_stage1', 'epochs_stage2', 'epochs_stage3'))\n",
    "\n",
    "    loss_data.to_netcdf(f'diagnostics/loss_data_{channel}_ocean.nc', engine='netcdf4')\n",
    "\n",
    "    print(f'Finished training model for channel {channel}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761d4567",
   "metadata": {},
   "outputs": [],
   "source": [
    "#General parameters:\n",
    "input_size = nchans - 1 + 1 #Remaining channels + surface type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9462d9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "GMI CHANNEL PREDICTION MODEL:\n",
    "    2: Non-Ocean Surfaces\n",
    "\n",
    "'''\n",
    "\n",
    "with xr.open_dataset(f'{paths.training_datapath}/{sensor_info.satellite}_training_data.nc') as f:\n",
    "    \n",
    "    sfctype = f.sfctype.values\n",
    "\n",
    "    correct_sfc = sfctype > 1\n",
    "\n",
    "    Tbs = f.Tbs.values[correct_sfc,:]\n",
    "    sfctype = sfctype[correct_sfc]\n",
    "\n",
    "#---Split data into train/test/val:\n",
    "train_indcs, test_indcs, val_indcs = training_funcs.split_data_indcs(Tbs)\n",
    "\n",
    "Tbs_train = Tbs[train_indcs]\n",
    "Tbs_test  = Tbs[test_indcs]\n",
    "Tbs_val   = Tbs[val_indcs]\n",
    "\n",
    "sfctype_train = sfctype[train_indcs].astype(np.float32)\n",
    "sfctype_test  = sfctype[test_indcs].astype(np.float32)\n",
    "sfctype_val   = sfctype[val_indcs].astype(np.float32)\n",
    "\n",
    "#---Shuffle before converting to tensors:\n",
    "np.random.seed(40)\n",
    "Tbs_train, shuffled_indcs = training_funcs.shuffle_data(Tbs_train, axis=0, return_indcs=True)\n",
    "sfctype_train = sfctype_train[shuffled_indcs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d45e6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Predict channels: Train all models\n",
    "'''\n",
    "\n",
    "torch.set_num_threads(ncpus)\n",
    "\n",
    "for ichan, channel in enumerate(sensor_info.channel_descriptions):\n",
    "\n",
    "    print(channel)\n",
    "\n",
    "    #---Extract channel, x = predictors, y = channel to predict\n",
    "    x_train, y_train = extract_channel(Tbs_train, channel)\n",
    "    x_test,  y_test  = extract_channel(Tbs_test, channel)\n",
    "    x_val,   y_val   = extract_channel(Tbs_val, channel)\n",
    "\n",
    "    x_train = np.concatenate((x_train, sfctype_train[:,None]), axis=1)\n",
    "    x_test  = np.concatenate((x_test,  sfctype_test[:,None]), axis=1)\n",
    "    x_val   = np.concatenate((x_val,   sfctype_val[:,None]), axis=1)\n",
    "    \n",
    "    x_train, y_train = torch.tensor(x_train), torch.tensor(y_train)\n",
    "    x_test,  y_test  = torch.tensor(x_test), torch.tensor(y_test)\n",
    "    x_val,   y_val   = torch.tensor(x_val), torch.tensor(y_val)\n",
    "\n",
    "\n",
    "    #---Set up dataloaders:\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=dataset(x_train,y_train), \n",
    "                                               batch_size=batch_size, \n",
    "                                               shuffle=True, drop_last=True)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=dataset(x_test,y_test), \n",
    "                                               batch_size=None, \n",
    "                                               shuffle=False, drop_last=False)\n",
    "    val_loader = torch.utils.data.DataLoader(dataset=dataset(x_val,y_val), \n",
    "                                               batch_size=None, \n",
    "                                               shuffle=False, drop_last=False)\n",
    "    \n",
    "    #---Create model:\n",
    "    model = channel_predictor(input_size, hidden_size, output_size)\n",
    "\n",
    "    #---Train_model:\n",
    "    nbatches = len(train_loader)\n",
    "    nepochs_stage1 = 5\n",
    "    nepochs_stage2 = 10\n",
    "    nepochs_stage3 = 20\n",
    "\n",
    "    loss_stage1, valloss_stage1 = training_funcs.train_model(model, \n",
    "                                                             nepochs=nepochs_stage1, \n",
    "                                                             dataloader=train_loader, \n",
    "                                                             learning_rate=0.001, \n",
    "                                                             quiet=False, \n",
    "                                                             stage=1, \n",
    "                                                             validation_dataloader=val_loader)\n",
    "    \n",
    "    loss_stage2, valloss_stage2 = training_funcs.train_model(model, \n",
    "                                                             nepochs=nepochs_stage2, \n",
    "                                                             dataloader=train_loader, \n",
    "                                                             learning_rate=0.001, \n",
    "                                                             quiet=False, \n",
    "                                                             stage=2, \n",
    "                                                             validation_dataloader=val_loader)\n",
    "    \n",
    "    loss_stage3, valloss_stage3 = training_funcs.train_model(model, \n",
    "                                                             nepochs=nepochs_stage2, \n",
    "                                                             dataloader=train_loader, \n",
    "                                                             learning_rate=0.001, \n",
    "                                                             quiet=False, \n",
    "                                                             stage=3, \n",
    "                                                             validation_dataloader=val_loader)\n",
    "\n",
    "    torch.save(model.state_dict(), \n",
    "               f'{model_path}/{sensor}/{sensor}_{satellite}_channel_predictor_{channel}_nonocean.pt')\n",
    "\n",
    "    loss_data = data2xarray(data_vars = (loss_stage1, loss_stage2, loss_stage3, \n",
    "                                     valloss_stage1, valloss_stage2, valloss_stage3),\n",
    "                        var_names = ('LossStage1','LossStage2','LossStage3',\n",
    "                                     'ValidationLossStage1', 'ValidationLossStage2', 'ValidationLossStage3'),\n",
    "                        dims = (nbatches,nepochs_stage1,nepochs_stage2, nepochs_stage3),\n",
    "                        dim_names = ('training_batches', 'epochs_stage1', 'epochs_stage2', 'epochs_stage3'))\n",
    "\n",
    "    loss_data.to_netcdf(f'diagnostics/loss_data_{channel}_nonocean.nc', engine='netcdf4')\n",
    "\n",
    "    print(f'Finished training model for channel {channel}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70854234",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
